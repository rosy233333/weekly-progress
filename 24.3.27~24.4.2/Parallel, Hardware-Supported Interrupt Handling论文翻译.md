# Parallel, Hardware-Supported Interrupt Handling论文翻译

时间：2024/3/28

原文：[https://dl.acm.org/doi/10.1145/1629395.1629419](https://dl.acm.org/doi/10.1145/1629395.1629419)

# 事件触发、实时操作系统中的并行、硬件支持的中断处理

## 摘要

事件触发的实时系统中的一个常见的问题，就是实现为中断处理程序的低优先级任务会中断实现为线程的高优先级任务。这个问题被称为单调速率优先级倒置，而当前基于软件的解决方案在更复杂的调度器功能方面受到限制，正如AUTOSAR嵌入式操作系统规范所要求的那样。

我们提出了一个基于硬件的方案，其可以利用一个协处理器来消除可能的优先级倒置。我们通过评估它的一个原型实现，展示我们的方案不仅克服了软件方案的限制，也用很小的处理开销换来了更好的可预测性。

## 类型和学科描述符

C.3【**特殊用途和基于应用的系统**】：实时系统和嵌入式系统；D.4.1【**操作系统**】：进程管理——*线程*；D.4.7【**操作系统**】：组成与设计——*实时系统和嵌入式系统*

## 一般术语

设计，性能

## 关键词

CiAO操作系统，实时系统，优先级驱动，单调速率优先级倒置，TriCore微控制器，中断处理

## 1. 引言

除了功能正确性之外，及时性时实时系统最重要的属性，因为无法按时交付的结果可能与错误的结果产生相同的影响。因此，提前进行可调度性分析，以确保所有带着硬性截止时间的任务可以按时完成，是必要的。系统整体的可预测性越好，这样的可调度性分析越可能得出精确和可靠的结果。

### 1.1. 单调速率优先级倒置

不幸的是，现有的事件触发系统维护的优先级空间被分裂成两部分：硬件管理着中断的优先级，而操作系统管理着线程的优先级。Leyva-del-Foyo等人说明，实时系统会因为这种二分的优先级空间受到严重影响[5]：与低优先级或者软实时的任务相关的中断，可能打断高优先级的硬实时任务。这会严重影响高优先级任务的响应时间，以至于它们可能无法在截止时间前完成。这种由实现为中断处理程序的低优先级任务引起的干扰被称为*单调速率优先级倒置（rate-monotonic priority inversion）*。对这样的软实时任务的出现频率，通常只能做非常弱的假设，这同时也让系统的行为更不可预测了。因此，可调度性分析的结果也会有更低的精确度，以及更悲观的结果。

为了解决这个问题，Leyva-del-Foyo等人建议将所有任务实现为线程，并且用很简短的中断处理程序来触发它们，例如，通过设置信号量[5, 6]。更进一步地，在软件中实现的中断分级机制能通过屏蔽低优先级的中断源来杜绝这些中断处理程序的干扰。然而，这样的方案不适合需要更复杂的调度器功能，比如存储一个程序的多个激活实例或者允许多个任务使用相同的优先级，的系统。例如，被汽车微控制器广泛使用的AUTOSAR-OS标准[2]，就规定了这些功能。

### 1.2. 并行、硬件支持的中断处理

我们的方法*基于硬件*，并且使用不屏蔽任何中断的方法阻止了不必要的打断。相反，我们将中断请求重定向到协处理器，让它们与正常的程序并行处理。我们的方案改进了Leyva-del-Foyo等人的方案，解决了其中的缺陷：

- 可以同时储存*任务的多个激活实例*。而在基于软件的方案中，每个任务只有一个额外的激活实例可以被硬件缓存。
- 多个任务可以*共享相同的优先级*，同时保留它们被激活的顺序。基于软件的方案无法做到这一点。
- 事件发生时，我们不使用信号量通知任务。在基于软件的方案中，显式等待信号量使*栈共享技术*无法实现，而这一技术在嵌入式系统中广泛地用于节省紧张的内存资源。

![](../图片/parallel,%20hardware-supported_Fig1.png)

第2节对我们的方法做了详细介绍，并说明了它相比基于软件的方法的改进。我们在TriCore微控制器上的CiAO操作系统中实现了我们方案的原型（见第3节），并评估了它的性能（见第4节）。第5节列出了我们的方法的相关工作。第6节讨论了我们方法的几个方面——例如我们方法的中断过载问题，以及它的通用性。

## 2. 设计

图1展示了我们设计的概要；它需要一个与主CPU并行工作的额外硬件。该硬件需要处理其它外部硬件提出的中断请求、访问调度器数据结构，以及向CPU发送一种信号——例如，通过处理器间中断。因为我们实现的平台是TriCore微控制器，我们使用外部设备控制处理器（peripheral control processor，PCP）作为该硬件，不过任何具有相似属性的硬件都可以用于该用途。

我们消除单调速率优先级倒置的方法是将所有硬件中断请求重定向到PCP，并在PCP上处理它们。之后，我们配置中断控制系统，构建从任务优先级到中断优先级的映射，从而构造统一的优先级空间，而统一的优先级空间是避免单调速率优先级倒置所必须的。支持这些功能的中断控制系统在当前技术水平的，用于嵌入式系统的微控制器中很常见，TriCore就是其中之一。映射自身是依靠程序完成的，只需要合适地初始化中断系统即可。

PCP协处理器上的中断处理有责任唤醒与给定中断源相关的任务。为了进行这一唤醒操作，PCP需要访问调度器的数据结构。当且仅当被唤醒的任务的优先级是系统的就绪任务中最高的，PCP才会通知CPU需要调度一个不同的线程。该通知是通过向CPU发起一个*异步系统陷入（asynchronous system trap，AST）*实现的。AST被实现为*CPU上的*中断处理程序，功能仅是触发CPU的重新调度。与在PCP上执行的ISR（interrupt service routine，中断服务程序）不同，AST只会在更高优先级的任务就绪时触发，触发时只会通知CPU。因此，它自身不会引起单调速率优先级倒置。

### 2.1. PCP中断处理程序的设计

![](../图片/parallel,%20hardware-supported_Fig2.png)

当每个中断请求发往PCP时，执行的中断处理程序的控制流结构如图2所示。

首先，确认发出当前请求的中断源。之后，从程序配置中查找并唤醒与这个中断源相关的任务。最后，将当前运行任务的优先级与刚才唤醒的任务的优先级比较，*在必要时*使用处理器间中断通知CPU进行重新调度。

为了让唤醒高优先级任务的开销尽量小，PCP上的ISR可以被高优先级的中断请求打断。这与PCP上的ISR和CPU上的任务*并行*执行都表明了对常用数据结构的同步访问的必要性。通过保证两个临界区CS1和CS2的互斥访问（见图2）达到同步的效果。这些临界区被两个嵌套的锁管理。外层的PCP锁通过锁定PCP上的中断以防止ISR被高优先级的中断请求打断。内部的锁通过Peterson的算法，一个基于自旋锁的互斥访问算法[9]，保证对调度器的互斥访问。PCP锁需要在调度器锁之前获取；否则，如果ISR试图获得被另一被打断的ISR已经获得的调度器锁，就会引起死锁。

我们决定连续，而非分离地保证CS1、CS2两个临界区。因为我们在内核和中断处理函数的同步中使用了Peterson的算法，中断处理程序每次试图获得调度器锁时都可能被内核阻塞。此时引入的阻塞时延可能比CS1、CS2两个临界区共同的处理时间还长。（同时见4.3节）

ISR的开始（prolog）阶段不需要同步，因为我们实现的平台是静态配置系统，例如AUTOSAR OS[2]或OSEK OS[17]；即是说，中断源的连接不会在运行时改变。

然而，将中断请求关联的任务唤醒（CS1临界区）显然需要同步。它需要保证不被其它中断源的请求打断，因为它们同样会唤醒任务，因而会操作相同的数据结构。唤醒操作同样需要与来自CPU的交错访问同步，因为CPU上执行的任务也能以同步的方式修改调度器数据结构——例如，当任务结束时。

第二个临界区（CS2）需要同步，原因是防止CPU上的单调速率优先级倒置。假设当前ISR在检查是否需要重新调度之后、告知CPU需要重新调度的结果之前被打断，那么主动打断的高优先级ISR与被打断的低优先级ISR都会发出中断。这会导致CPU接受到的一个中断不会带来任务切换，因为CPU已经重新调度、切换到了高优先级的任务。额外的调度器锁也是必要的，因为CPU上的任务可能改变系统状态，使得重新调度不再必要——例如，通过激活和调度一个最高优先级的任务。这个情形也会导致CPU接收到一次不必要的中断，其可以被理解为单调速率优先级倒置。

由此，PCP中断处理程序的设计杜绝了单调速率优先级倒置，同时尽可能减少了中断时延。

### 2.2. 相较基于软件的设计的优势

与避免单调速率优先级倒置的基于软件的方法（例如在[5]中提出的）相比，并行中断处理的方法不需要屏蔽低优先级的中断。这是因为本方法中的任务分级是由硬件的中断系统，而非软件实现的。而硬件的中断系统本身就是为该目的而设计的。

我们的方法因此带来了一些显著的概念优势。

#### *2.2.1. 同一任务的多个激活实例*

类似[5]的行为，屏蔽或取消屏蔽中断源以避免单调速率优先级倒置，导致了在处理被唤醒不止一次的任务时的不灵活，正如图3（a）的例子。图中展示了两个任务T1和T2，T1的优先级高于T2。在t1时刻，任务T1被第一次唤醒，也因此抢占了真正运行的任务T2。在任务T1执行过程中，其又分别在t2和t3时刻各被唤醒了一次。在t2时刻的第一次唤醒可以被中断系统储存（假设使用了等级触发的中断系统），但t3时刻的第二次唤醒一定会丢失。因此，当T1在t4时刻终止时，它只会被重新执行一次。

我们的方法不会被这一限制影响，就像图3（b）中对同一例子演示的那样。因为没有中断源被屏蔽，t2和t3时刻的中断请求可以被PCP服务，使任务T1被唤醒两次，并在t4时刻后额外执行两次。因此，例如AUTOSAR-OS标准要求的那样，任意多次唤醒同一任务的情形，只要调度器支持就可以处理。

#### *2.2.2. 同一优先级的多个任务*

基于软件的方法在处理多个任务共享同一优先级的情况同样能力有限，正如图4（a）的演示。在t2和t3时刻，两个相同优先级的低优先级任务T2和T3被唤醒；中断请求被硬件缓存，因为那时中断源被屏蔽了。因此，在任务T1在t4时刻终止时，T2和T3谁先执行只由硬件决定。

而我们的方法则保留了任务唤醒的顺序，正如图4（b）的演示。因为中断未被屏蔽，任务可以按照它们出现的顺序唤醒，也按照这个顺序放入调度器。因此，例如AUTOSAR-OS标准要求的那样，共享同一优先级的不同任务可以按照它们到来的顺序被处理。

#### *2.2.3. 栈共享*

基于软件的设计不仅限制了调度器功能，也阻碍了栈共享技术，一个在嵌入式系统中广泛地用于节省紧张的内存资源的技术，的实施。软件的分级要求所有事件处理函数都是被调度器管理的线程，并在事件发生时通过单侧同步机制，例如被硬件上运行的ISR发出的信号量告知。因此，每个线程需要等待一个相应的信号量，这种阻塞式、单侧的同步让栈共享的实施变得低效[12]。

我们的方法不需要阻塞式的操作系统原语，不对栈共享产生限制，也因此优化了系统的内存使用。

## 3. 实现

我们在TriCore微控制器平台上，通过扩展CiAO研究操作系统，实现了我们方案的原型。在接下来的小节中，我们会描述操作系统的环境、硬件平台的相关特点，以及中断处理程序实现的细节。

### 3.1. CiAO系统

CiAO（CiAO is Aspect-Oriented，CiAO是面向方面的）是一类可配置的操作系统，它们用于嵌入式和深嵌系统，支持将在下文详细描述的TriCore硬件平台[14]。我们用于扩展和评估的指定系统源于OSEK-OS[17]和AUTOSAR-OS[2]标准。它因此实现了一个事件触发的操作系统，其使用带有多级队列、没有时间片、静态分配线程优先级的调度器。

在基本配置中，适用于TriCore平台的CiAO内核通过在进入内核时，将中断优先级提高到最高优先级的ISR的优先级，退出内核时将其重置为0的方式，实现内核与ISR的同步。通过这种方式，这段时间内的ISR触发会被推迟，直到退出临界区。在本文所述的扩展中，执行任务的CPU只会被一种中断打断：由PCP触发的异步系统陷入（AST）。因此，内核通过在系统调用期间，将中断优先级设置为AST的优先级的方式，与AST进行同步。

因为CiAO使用面向方面编程（aspect-oriented programming，AOP[10]）的技术实现——即AOP语言和AspectC++织入器[19]——对内核的修改实现为一个单独的、封装好的方面模块。该方面包括将内核与AST（如上文所述）和PCP（使用Peterson的算法，见2.1节）同步的代码。使用*量化*这一AOP功能，对系统的横切交错的修改（每个系统调用都需要配备同步代码）可以封装在精简和因此可维护的代码中。

![](../图片/parallel,%20hardware-supported_Fig3-4.png)

### 3.2. TriCore平台

我们的原型在TriCore TC1796微控制器上实现，正如之前提到的，该硬件具有实现我们的设计需要的所有功能。TriCore的外部设备控制处理器（peripheral control processor，PCP）提供一个与主处理器并行执行的线程，可以用于中断处理。在TriCore架构中，中断源用服务请求节点（service request nodes，SRNs）表示。每个SRN可以分配给一个服务提供者（CPU或者PCP），并且指定一个中断等级。因此，SRN可以被静态配置为直接使用硬件实现中断分级方案，正如第2节的描述。PCP和主CPU间的数据交换通过在特殊的总线间共享的内存完成；该内存在两个处理器中被映射到不同的位置。

我们配置该系统，从而让所有外部中断发往PCP而非主处理器。在PCP上运行、直接响应中断的程序按照我们在2.1章的设计实现，其会在接下来的小结详细描述。唯一仍然发往CPU的中断用于触发AST。该机制由PCP使用，在比正在运行的任务优先级更高的任务被激活时，触发主处理器上的重新调度。

为了将被调度器管理的线程、中断源、被PCP管理的ISR相联系，我们使用一个存储在共享内存中的表格，将线程映射到中断源。该表格在系统启动时初始化。

### 3.3. PCP中断处理程序的实现

PCP中断处理程序的实现被分为三部分，如图2所示。

因为多中断源的确认由TriCore平台的硬件自动完成，开始（prolog）阶段只包括获取和修改操作系统中的数据结构前的必要准备工作。它们包括查询静态数据，例如当前中断请求的所属线程的优先级，或者内核调度器数据结构，例如线程的就绪列表的地址。因为这些都是对静态数据的只读操作，这一部分可以被更高优先级的PCP中断处理程序或者TriCore CPU上运行的主程序流打断。

在第一个临界区CS1期间，处理程序将与当前中断源相关的线程加入调度器的就绪队列中。这部分使用了开始阶段查询到的信息。

在第二个临界区CS2中，如果重新调度是必要的，PCP需要向CPU发送信号。为了确定是否是这种情况，它需要检查新唤醒的线程是否有比正在执行的线程更高的优先级。除此之外，它还要确认就绪队列中没有更高优先级的线程，因为如果更高优先级的线程在就绪队列中，它会马上被调度运行——将系统的优先级提高到它的优先级，使AST不再必要。如果这两种情况都不满足，我们的线程事实上优先级最高，则PCP向主处理器发送AST以触发重新调度。这一设计通过将是否发送AST的决定和发送AST的过程都原子化，确保每个发送的AST都一定会引起一次主处理器的重新调度，因为在AST触发前，没有其它线程会被唤醒。这一性质因此杜绝了单调速率优先级倒置。

对临界区CS1和CS2的保证在2.1章中描述。它通过在执行流离开临界区前禁用中断，避免了更高优先级PCP程序的打断。使用Peterson的算法实现的自旋锁，避免PCP和CPU对调度器数据结构的同时访问。

## 4. 实验评估

我们以两个目的详细地评估我们的原型：一方面，我们证明我们的原型杜绝了低优先级和软实时的ISR的*多余的*干扰，另一方面，我们量化了我们实现的统一优先级空间带来的开销。

### 4.1. 实验方法

在我们的实验中，我们使用一块Infineon的TriBoard TC1796，其具有TriCore TC1796微控制器。它的时钟频率为50MHz，导致其中断周期为20*ns*。我们使用Lauterbach TRACE32硬件调试器与追踪器来精确测量CPU的所有执行事件，但追踪功能无法用于PCP。因此，为了测量PCP，我们改变I/O引脚的电平并使用数字存储示波器来确定I/O引脚上斜率的持续时间。我们使用一个函数发生器产生不同频率的方波信号来模拟TC1796的I/O引脚上的外部事件。为了测量，我们独占使用TC1796的内部、无等待状态的RAM，以存储代码和数据。

### 4.2. 行为

我们第一部分的评估显示我们的原型的确可以防止单调速率优先级倒置为CPU带来的多余干扰。我们合成的任务集如表1所示；其包括一个硬实时任务T1和一个软实时，却可能干扰T1的任务T2。在一个情景中，我们将软实时任务实现为传统的二分裂的优先级空间中的ISR。在另一个情景中，我们将它实现为使用我们并行中断处理原型的线程。

我们测量了实时任务在操作系统具有二分裂的优先级空间的传统中断处理方法，以及在中断和任务具有统一优先级空间的我们的实现，这两种情形下的反应时间。我们通过检查TRACE32调试器生成的执行追踪，以及同样使用该调试器测量任务T1的运行时间，来确认我们的原型按预期工作。

![](../图片/parallel,%20hardware-supported_Tab1-Fig5.png)

实验获取的，传统中断处理实现和我们原型的实现的响应时间分布分别如图5（a）和（b）描述。可以明显地看出，传统实现的响应时间显著地更高，并且有明显的抖动。这些现象由T1被软实时的ISR T2干扰引起。如果我们以浮动的速率生成外部事件，抖动甚至会更大。但由于可行性的原因，我们以2 ms的固定周期触发ISR，如表1所示。

与之相反，使用我们的原型实现的并行中断处理取得了明显更优的结果。响应时延低到几乎等于任务执行时间，以及很小的抖动（由测量误差引起）都表明T1不再被软实时任务干扰。我们同样能用之前提到的执行追踪证明这个干扰不再发生。

### 4.3. 开销

为了评估我们方法的代价，我们量化了我们方法相较于传统中断处理以及基于软件的方案的开销，使用的方式是比较在响应外部事件时的最好与最坏情况的时延。我们用一个等待信号量的线程来模拟基于软件的方案；该信号量由被外部事件触发的ISR发送。测量到的时延如表2所示。

这些时延的构成如图6所示。需要强调，硬件时延HW在每次出现时波动不大。然而，我们无法精确地确定这些硬件时延，因此硬件时延只是为了演示而提及。传统中断处理的最好情况时延只包括操作系统进行的中断上下文管理，也因此远远短于基于软件的方案和我们的并行中断处理。基于软件的方案和我们的并行中断处理实现只在最终触发CPU的AST的中断处理程序处不同。在基于软件的方案中，该中断处理程序在CPU上执行，而在我们的并行中断处理中，它在PCP上执行，导致了在最好情况下平均263*ns*的开销。

![](../图片/parallel,%20hardware-supported_Tab2-Fig6.png)

最坏情况下的时延，如表2所示，来源于事件处理函数可能经历的额外阻塞。出于公平比较的原因，我们假设所有实现都需要与OS内核同步，以保护OS内部的数据结构。传统中断处理和基于软件的方案的事件处理函数可能被最多一个向OS内核发出的系统调用阻塞。在基于软件的方案中，AST自身不会被内核阻塞，因为它是在相同的处理器上运行的；因此，这一阻塞时间由时间最长的系统调用决定。在CiAO OS中，最长的系统调用耗时*OSmax*=5.760*us*，导致最坏情况的时延*wc*=*bc*+*OSmax*如图2所示。在并行中断处理中，PCP中的中断处理函数和AST都可能需要等待调度器锁的获取。因此，事件处理函数可能被内核阻塞两次。因为PCP上的中断处理函数需要与其它覆盖执行的其它中断请求同步（见2.1章），在临界区CS1和CS2内，中断被锁定，导致了一个与临界区执行时间CS=2.390*us*相等的额外阻塞时间。

如果我们分离地保证CS1和CS2（同样见2.1章），PCP上的中断处理函数可能在CS2的入口处被额外阻塞一次，使最坏情况时延*wc*=*bc*+3·*OSmax*+CS=28.995*us*。因此，连续地锁定CS1和CS2降低了最坏情况下的时延5.760*us*，而只是稍微增加了CPU的阻塞时间（小于2.390*us*）。

另一方面，在CPU上运行的线程也可能被在临界区CS1和CS2中拥有自旋锁的PCP阻塞。其可能经受的最大阻塞时间总计CS=2.390*us*，且在线程每次发出系统调用时都可能发生。这一阻塞带来的性能影响当然会随着PCP和CPU的性能差距增大而增大。为了应对这一点，我们保证PCP上执行的代码量尽可能小。此外，可以分离地保证临界区CS1和CS2。在此方法中，我们用CPU的阻塞时间延长换取在响应外部事件时更优的最大时延。

因此，在最优情况下，我们的方案相较于基于软件的方案基本没有引入额外的开销，但它在一般的OS规范要求了更复杂的调度器功能的情况下，以及在栈共享的情况下，都更加灵活，正如2.2章所述。由于PCP和CPU间的同步需求增加，我们的并行中断处理在最坏情况下比基于软件的方案表现更差，但如果对可预测的系统行为和更复杂的功能有需求，这是一个可承受的代价。进一步地，需要注意，在并行中断处理中，最差情况发生的频率很低。它需要两个相邻发生的系统调用，而在基于软件的方案中，一个系统调用就会达到最差情况。

## 5. 相关工作

中断为实时系统带来的可预测性问题是实时系统研究的一个特定领域的目标。许多方案试图忽略*多余的*中断请求[2, 18]。对于每个中断源，需要确定最小到达间隔时间、最大到达速率、最大连续传输长度等参数。之后，这些参数在一般的操作中被监测。不能适应这些给定参数边界条件的中断被视为*多余的*中断并被忽略。这样的方案对于防止和限制中断带来的过载情况很有效，但它们并未解决由二分裂的中断空间带来的问题。高优先级的硬实时任务仍然可能被干扰，例如被实现为ISR的软实时任务干扰。我们的方案在一定程度上也会受到PCP的中断过载的影响。然而，通过使用*以上*提到的技术，可以为PCP提供额外的，对中断过载的防护。在主处理器上执行的应用程序自身，可以自动防护过载的情况，正如那些统一优先级空间的方法。因为调度器控制了主处理器上的所有活动，可以采用零星服务器[20]等手段限制为异步事件的处理函数分配的时间。

不对称多处理器的概念当然在之前就已被操作系统社区使用。专门化的协处理器也已被用于在特定任务上支持操作系统。然而，这些方法的主要目标是最大化操作系统的吞吐率和效率。例如，流行的应用场景为消息传递系统中的延迟隐藏[3]或者网络协议卸载[11]。提供与我们相关的方案的操作系统内核是Stankovic和Ramamritham的Spring内核[21]。它在独立的I/O子系统中使用被称为前端处理器的不对称多处理器方法以卸载中断的处理。此方法可以有效避免单调速率优先级倒置。然而，Spring内核的设计用途是只在非抢占的方式下运行任务。因此，它不适用于任何的实时系统——例如AUTOSAR OS的实现。

存在其它试图使用硬件抽象协助操作系统调度器的方法；然而，它们基本都依赖于*自定义硬件*。它们的方法——包括cs2[15]、FASTCHART[13]、Silicon TRON[16]、HW-RTOS[4]和Atalanta[22, 1]——通过在FPGA上综合特殊的电路，并且将其功能通过类似协处理器的方法提供，从而将操作系统的功能移动到硬件层面。它们中的一些方案，作为副产物，也防止了单调速率优先级倒置，但没有一个方案显式说明了这一点。与之不同，我们的方法没有在硬件中实现专用的调度器函数；相反，我们使用了*现有的商品硬件*实现统一的优先级空间（见6.3章），因此防止了单调速率优先级倒置。

## 6. 讨论

在本章节中，我们讨论中断过载问题的可能后果以及它如何影响我们的方法、在PCP上直接执行线程和ISR的可能性，以及我们方法的通用性。

### 6.1. 中断过载

正如在之前的章节中提到的，我们的方法依然会受到PCP上中断过载情况的影响——高优先级的中断会占满PCP。然而，基于软件的方法，例如[5, 6]提出的，同样有这一问题。在那些方法中，需要使用一个小的ISR来通知与当前事件相关的任务——这个ISR可能会占满CPU。

对两种方法都适用的一个可能的解决方案是将零星服务器算法扩展成也影响中断源。当服务器的执行预算耗尽，不仅需要调度器推迟对零星服务器之后的唤醒，还需要重新配置触发该零星服务器的中断源。这些中断源在没有执行预算时，需要被禁用或者降低优先级，取决于使用的零星服务器算法的具体实现。因此，该任务无法通过ISR消耗零星服务器分配的计算时间之外的计算时间，从而有效避免了中断过载。

### 6.2. 在PCP上运行线程和ISR

PCP提供了一个与CPU完全独立的控制流，由此产生了将线程和ISR一同在PCP上运行的想法。然而，出于两个原因，我们没有这么做。

第一，在PCP上运行线程会在PCP中引入单调速率优先级倒置。考虑到我们使用PCP的目的是*防止*单调速率优先级倒置，这并不是合理的选择。即使将硬实时和软实时任务分离，将它们运行在不同的核心（例如，CPU和PCP）上，也不会完全消除单调速率优先级倒置。虽然软实时任务的中断是可以容忍的，但不同优先级的硬实时任务也会产生单调速率优先级倒置。因此，单独使用这个方法无法解决单调速率优先级倒置的问题，但它可以用于减少CPU和PCP的处理器间同步。

第二，PCP的计算能力远小于CPU，它是为很简单的任务，例如控制DMA传输或者中断预处理，而设计的，而我们使用PCP也出于这些目的。

### 6.3. 通用性

我们已在Infineon-TriCore微控制器上的CiAO操作系统中实现了我们的方法。但该方法的概念本身可以用于十分广泛的硬件架构和OS内核。首先，几乎每个多核处理器或者多处理器系统都适合实现该概念，只要中断源的优先级可以在需要时配置。例如，汽车领域使用的很多微控制器的中断子系统都支持这些功能。其次，有很多其它的微控制器都配备了与TriCore架构的PCP相似的协处理器。例如S12X微控制器的XGATE协处理器[7]，或者MPC5510协处理器类和它们由Freescale提供的I/O协处理器[8]。

我们当前的实现，显然与实际使用的硬件绑定。但将我们的概念引入其它的架构，只需付出很少的努力。首先，它在操作系统中透明地实现，不会影响到应用程序本身。其次，只有很小一部分依赖于硬件的部分需要移植：在协处理器上运行的中断处理函数、通知CPU的机制，以及外设硬件初始化的组件。在我们的原型中，这些部分总共只有187行代码。这一数字主要源于PCP中断处理函数，因为它没有C/C++编译器而使用汇编语言编写。

考虑到其对其它OS内核的适用性，任何事件驱动的RTOS内核都适合使用并行中断处理的概念从而维护统一的优先级空间。唯一的要求是需要一个特殊中断，用于触发CPU运行的内核的重新调度。

## 7. 总结

我们证明了，可以利用商用嵌入式硬件，例如Infineon-TriCore平台，的协处理器阻止单调速率优先级倒置。相较于原有的基于软件的方案，我们的硬件支持的方法展现了重大的概念优势；这些优势包括进行栈共享的可行性、支持任务的多个激活实例，以及支持同一优先级的多种任务——例如，AUTOSAR嵌入式OS标准要求这些内容。除此之外，通过评估我们方法在CiAO操作系统上的实现，我们证明了该概念杜绝了由低优先级事件的中断引发的干扰。我们的方案仅仅轻微增加了开销，而为了提高对任何实时系统都至关重要的可预测性，这只是一点小小的代价。

## 8. 参考文献

略